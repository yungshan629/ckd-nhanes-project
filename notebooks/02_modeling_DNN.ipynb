{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0917cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SDMVSTRA', 'DMDEDUC2', 'SDMVPSU', 'year_group', 'RIDEXMON', 'SIAINTRP', 'FIALANG', 'RIDRETH1', 'RIAGENDR', 'RIDRETH3'] ...（共 59 個特徵）\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8620, 61), (2155, 61))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 載入處理好的資料\n",
    "df = pd.read_csv(\"../data/processed/nhanes_2013_2020_ckd_cleaned.csv\")\n",
    "\n",
    "\n",
    "# 要排除的變數（實際存在於資料中的才會排除）\n",
    "exclude_cols = [\n",
    "    \"SEQN\", \"id\", \"ckd\",               # 標籤與識別碼\n",
    "    \"URXUMA\", \"URXUCR\", \"ACR\",         # 尿液衍生欄位（洩漏標籤）\n",
    "    \"URDACT\", \"URDUCRLC\", \"URDUMALC\", \"SDDSRVYR\"   # 尿液其他延伸欄位（註解欄位）\n",
    "]\n",
    "exclude_cols = [col for col in exclude_cols if col in df.columns]\n",
    "\n",
    "# 分出 X 和 y\n",
    "X = df.drop(columns=exclude_cols)\n",
    "y = df[\"ckd\"]\n",
    "\n",
    "# 顯示特徵欄位前 10 項與總數\n",
    "feature_list = X.columns.tolist()\n",
    "feature_count = len(feature_list)\n",
    "print(feature_list[:10], f\"...（共 {feature_count} 個特徵）\")\n",
    "\n",
    "\n",
    "\n",
    "# 分類欄位（根據 pandas 自動推斷 object 或 category）\n",
    "categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "# 數值欄位（剩下的）\n",
    "numeric_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "\n",
    "# 建立 ColumnTransformer：對數值欄位做標準化、類別欄位做 one-hot\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 分訓練 / 測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# 執行轉換\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# 輸出轉換後的形狀資訊\n",
    "X_train_transformed.shape, X_test_transformed.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51f1a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Classification Report (Logistic Regression):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.69      0.71      1293\n",
      "           1       0.57      0.61      0.59       862\n",
      "\n",
      "    accuracy                           0.66      2155\n",
      "   macro avg       0.65      0.65      0.65      2155\n",
      "weighted avg       0.66      0.66      0.66      2155\n",
      "\n",
      "🔲 Confusion Matrix:\n",
      "[[893 400]\n",
      " [340 522]]\n",
      "🎯 ROC AUC Score: 0.7091\n"
     ]
    }
   ],
   "source": [
    "# Logistic model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 建立並訓練 Logistic Regression（加 class_weight）\n",
    "logit_model = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=5.0,\n",
    "    class_weight={0: 0.8, 1: 1.2},\n",
    "    solver='liblinear',\n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "logit_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred = logit_model.predict(X_test_transformed)\n",
    "y_pred_proba = logit_model.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "# 評估\n",
    "print(\"📊 Classification Report (Logistic Regression):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"🔲 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(f\"🎯 ROC AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "057ca17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Classification Report (SVM RBF):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73      1293\n",
      "           1       0.60      0.62      0.61       862\n",
      "\n",
      "    accuracy                           0.68      2155\n",
      "   macro avg       0.67      0.67      0.67      2155\n",
      "weighted avg       0.68      0.68      0.68      2155\n",
      "\n",
      "🔲 Confusion Matrix:\n",
      "[[932 361]\n",
      " [331 531]]\n",
      "🎯 ROC AUC Score: 0.7238\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 建立 SVM（RBF Kernel）\n",
    "svm_rbf_model = SVC(\n",
    "    kernel='rbf',\n",
    "    C=1.0,              # 控制誤差容忍度（大一點 → 越少錯誤，但可能過擬合）\n",
    "    gamma='scale',      # 'scale' 自動計算 gamma，或改數值如 0.01、0.05 試\n",
    "    class_weight='balanced',\n",
    "    probability=True,   # 計算 AUC 要打開\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 訓練\n",
    "svm_rbf_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred = svm_rbf_model.predict(X_test_transformed)\n",
    "y_pred_proba = svm_rbf_model.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "# 評估\n",
    "print(\"📊 Classification Report (SVM RBF):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"🔲 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(f\"🎯 ROC AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df9281d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.4\n",
      "xgboost.sklearn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyungshan/Library/Python/3.9/lib/python/site-packages/xgboost/core.py:158: UserWarning: [23:19:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Classification Report (XGBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.72      0.73      1293\n",
      "           1       0.59      0.62      0.60       862\n",
      "\n",
      "    accuracy                           0.68      2155\n",
      "   macro avg       0.66      0.67      0.66      2155\n",
      "weighted avg       0.68      0.68      0.68      2155\n",
      "\n",
      "🔲 Confusion Matrix:\n",
      "[[925 368]\n",
      " [331 531]]\n",
      "🎯 ROC AUC Score: 0.7323\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "import xgboost\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(xgboost.__version__)\n",
    "print(XGBClassifier.__module__)\n",
    "# ⏳ 計算 scale_pos_weight\n",
    "neg, pos = (y_train == 0).sum(), (y_train == 1).sum()\n",
    "scale = neg / pos\n",
    "\n",
    "# ✅ 建立強化版 XGBoost 模型\n",
    "xgb_model = XGBClassifier(\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    scale_pos_weight=scale,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.03,\n",
    "    n_estimators=400,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "xgb_model.fit(X_train_transformed, y=y_train)\n",
    "\n",
    "# 🔍 預測\n",
    "y_pred = xgb_model.predict(X_test_transformed)\n",
    "y_prob = xgb_model.predict_proba(X_test_transformed)[:, 1]\n",
    "\n",
    "# 📊 評估報告\n",
    "print(\"📊 Classification Report (XGBoost):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 🔲 混淆矩陣\n",
    "print(\"🔲 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# 🎯 ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"🎯 ROC AUC Score: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e13ce81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Classification Report (Random Forest):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.68      1293\n",
      "           1       0.55      0.69      0.61       862\n",
      "\n",
      "    accuracy                           0.65      2155\n",
      "   macro avg       0.65      0.66      0.65      2155\n",
      "weighted avg       0.67      0.65      0.66      2155\n",
      "\n",
      "🔲 Confusion Matrix:\n",
      "[[812 481]\n",
      " [268 594]]\n",
      "🎯 ROC AUC Score: 0.7284\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# 建立並訓練 Random Forest（注意 class_weight）\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    class_weight={0: 0.7, 1: 1.3},\n",
    "    min_samples_leaf=10,\n",
    "    min_samples_split=20,\n",
    "    random_state=42\n",
    ")\n",
    "rf_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# 預測\n",
    "y_pred = rf_model.predict(X_test_transformed)\n",
    "y_pred_proba = rf_model.predict_proba(X_test_transformed)\n",
    "\n",
    "# 評估指標\n",
    "print(\"📊 Classification Report (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"🔲 Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(f\"🎯 ROC AUC Score: {roc_auc_score(y_test, y_pred_proba[:, 1]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6012d683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyungshan/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 0s - 4ms/step - accuracy: 0.6404 - loss: 0.0809 - val_accuracy: 0.6473 - val_loss: 0.0802\n",
      "Epoch 2/100\n",
      "108/108 - 0s - 957us/step - accuracy: 0.6788 - loss: 0.0760 - val_accuracy: 0.6497 - val_loss: 0.0792\n",
      "Epoch 3/100\n",
      "108/108 - 0s - 948us/step - accuracy: 0.6863 - loss: 0.0742 - val_accuracy: 0.6439 - val_loss: 0.0796\n",
      "Epoch 4/100\n",
      "108/108 - 0s - 950us/step - accuracy: 0.6972 - loss: 0.0730 - val_accuracy: 0.6485 - val_loss: 0.0800\n",
      "Epoch 5/100\n",
      "108/108 - 0s - 972us/step - accuracy: 0.7052 - loss: 0.0717 - val_accuracy: 0.6514 - val_loss: 0.0798\n",
      "Epoch 6/100\n",
      "108/108 - 0s - 944us/step - accuracy: 0.7101 - loss: 0.0706 - val_accuracy: 0.6555 - val_loss: 0.0801\n",
      "Epoch 7/100\n",
      "108/108 - 0s - 910us/step - accuracy: 0.7171 - loss: 0.0696 - val_accuracy: 0.6578 - val_loss: 0.0803\n",
      "Epoch 8/100\n",
      "108/108 - 0s - 912us/step - accuracy: 0.7227 - loss: 0.0685 - val_accuracy: 0.6520 - val_loss: 0.0808\n",
      "Epoch 9/100\n",
      "108/108 - 0s - 921us/step - accuracy: 0.7320 - loss: 0.0669 - val_accuracy: 0.6531 - val_loss: 0.0822\n",
      "Epoch 10/100\n",
      "108/108 - 0s - 921us/step - accuracy: 0.7364 - loss: 0.0664 - val_accuracy: 0.6386 - val_loss: 0.0831\n",
      "Epoch 11/100\n",
      "108/108 - 0s - 918us/step - accuracy: 0.7381 - loss: 0.0655 - val_accuracy: 0.6334 - val_loss: 0.0837\n",
      "Epoch 12/100\n",
      "108/108 - 0s - 913us/step - accuracy: 0.7512 - loss: 0.0641 - val_accuracy: 0.6357 - val_loss: 0.0846\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step\n",
      "DNN + Focal Loss Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.25      0.39      1293\n",
      "           1       0.45      0.92      0.61       862\n",
      "\n",
      "    accuracy                           0.52      2155\n",
      "   macro avg       0.64      0.59      0.50      2155\n",
      "weighted avg       0.68      0.52      0.48      2155\n",
      "\n",
      "Confusion Matrix:\n",
      "[[328 965]\n",
      " [ 65 797]]\n",
      "ROC AUC: 0.7083748293057567\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# 讀資料\n",
    "df = pd.read_csv(\"../data/processed/nhanes_2013_2020_ckd_cleaned.csv\")\n",
    "exclude_cols = [\"SEQN\", \"id\", \"ckd\", \"URXUMA\", \"URXUCR\", \"ACR\", \"URDACT\", \"URDUCRLC\", \"URDUMALC\"]\n",
    "exclude_cols = [col for col in exclude_cols if col in df.columns]\n",
    "X = df.drop(columns=exclude_cols)\n",
    "y = df[\"ckd\"]\n",
    "\n",
    "# 標準化 + OneHot\n",
    "categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "numeric_cols = [col for col in X.columns if col not in categorical_cols]\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_cols),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Focal Loss 定義\n",
    "def focal_loss(gamma=2., alpha=0.5):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, dtype='float32')\n",
    "        pt = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        return -K.mean(alpha * K.pow(1. - pt, gamma) * K.log(pt + K.epsilon()))\n",
    "    return loss\n",
    "\n",
    "# 建立 DNN 模型\n",
    "model = Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(X_train_transformed.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, loss=focal_loss(gamma=2., alpha=0.5), metrics=['accuracy'])\n",
    "\n",
    "# 提早停止\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# 訓練（不加 class_weight）\n",
    "model.fit(\n",
    "    X_train_transformed, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 預測 + threshold 調整\n",
    "y_pred_prob = model.predict(X_test_transformed).flatten()\n",
    "threshold = 0.4  # 調這裡\n",
    "y_pred = (y_pred_prob > threshold).astype(int)\n",
    "\n",
    "# 評估\n",
    "print(\"DNN + Focal Loss Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fd618a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyungshan/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chenyungshan/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/chenyungshan/Library/Python/3.9/lib/python/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 - 0s - 4ms/step - accuracy: 0.6563 - loss: 0.4145 - val_accuracy: 0.6578 - val_loss: 0.3539 - learning_rate: 5.0000e-04\n",
      "Epoch 2/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6781 - loss: 0.3006 - val_accuracy: 0.6549 - val_loss: 0.2579 - learning_rate: 5.0000e-04\n",
      "Epoch 3/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6898 - loss: 0.2196 - val_accuracy: 0.6549 - val_loss: 0.1920 - learning_rate: 5.0000e-04\n",
      "Epoch 4/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6910 - loss: 0.1655 - val_accuracy: 0.6537 - val_loss: 0.1494 - learning_rate: 5.0000e-04\n",
      "Epoch 5/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6888 - loss: 0.1314 - val_accuracy: 0.6555 - val_loss: 0.1232 - learning_rate: 5.0000e-04\n",
      "Epoch 6/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6904 - loss: 0.1104 - val_accuracy: 0.6578 - val_loss: 0.1075 - learning_rate: 5.0000e-04\n",
      "Epoch 7/100\n",
      "108/108 - 0s - 983us/step - accuracy: 0.6897 - loss: 0.0980 - val_accuracy: 0.6578 - val_loss: 0.0980 - learning_rate: 5.0000e-04\n",
      "Epoch 8/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6908 - loss: 0.0904 - val_accuracy: 0.6589 - val_loss: 0.0923 - learning_rate: 5.0000e-04\n",
      "Epoch 9/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6910 - loss: 0.0859 - val_accuracy: 0.6613 - val_loss: 0.0887 - learning_rate: 5.0000e-04\n",
      "Epoch 10/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6943 - loss: 0.0831 - val_accuracy: 0.6589 - val_loss: 0.0866 - learning_rate: 5.0000e-04\n",
      "Epoch 11/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6930 - loss: 0.0813 - val_accuracy: 0.6584 - val_loss: 0.0852 - learning_rate: 5.0000e-04\n",
      "Epoch 12/100\n",
      "108/108 - 0s - 2ms/step - accuracy: 0.6926 - loss: 0.0801 - val_accuracy: 0.6578 - val_loss: 0.0844 - learning_rate: 5.0000e-04\n",
      "Epoch 13/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6929 - loss: 0.0793 - val_accuracy: 0.6572 - val_loss: 0.0839 - learning_rate: 5.0000e-04\n",
      "Epoch 14/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6956 - loss: 0.0789 - val_accuracy: 0.6601 - val_loss: 0.0834 - learning_rate: 5.0000e-04\n",
      "Epoch 15/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6977 - loss: 0.0783 - val_accuracy: 0.6589 - val_loss: 0.0833 - learning_rate: 5.0000e-04\n",
      "Epoch 16/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6985 - loss: 0.0779 - val_accuracy: 0.6584 - val_loss: 0.0830 - learning_rate: 5.0000e-04\n",
      "Epoch 17/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6979 - loss: 0.0777 - val_accuracy: 0.6572 - val_loss: 0.0831 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.7008 - loss: 0.0774 - val_accuracy: 0.6572 - val_loss: 0.0832 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.7010 - loss: 0.0773 - val_accuracy: 0.6613 - val_loss: 0.0831 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.6995 - loss: 0.0771 - val_accuracy: 0.6607 - val_loss: 0.0832 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.7050 - loss: 0.0767 - val_accuracy: 0.6595 - val_loss: 0.0832 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.7091 - loss: 0.0760 - val_accuracy: 0.6636 - val_loss: 0.0831 - learning_rate: 2.5000e-04\n",
      "Epoch 23/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.7130 - loss: 0.0757 - val_accuracy: 0.6636 - val_loss: 0.0833 - learning_rate: 2.5000e-04\n",
      "Epoch 24/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.7153 - loss: 0.0755 - val_accuracy: 0.6601 - val_loss: 0.0834 - learning_rate: 2.5000e-04\n",
      "Epoch 25/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.7143 - loss: 0.0754 - val_accuracy: 0.6584 - val_loss: 0.0836 - learning_rate: 2.5000e-04\n",
      "Epoch 26/100\n",
      "108/108 - 0s - 1ms/step - accuracy: 0.7172 - loss: 0.0753 - val_accuracy: 0.6555 - val_loss: 0.0837 - learning_rate: 2.5000e-04\n",
      "\u001b[1m68/68\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step\n",
      "DNN 升級版 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.46      0.59      1293\n",
      "           1       0.51      0.83      0.63       862\n",
      "\n",
      "    accuracy                           0.61      2155\n",
      "   macro avg       0.65      0.64      0.61      2155\n",
      "weighted avg       0.68      0.61      0.60      2155\n",
      "\n",
      "Confusion Matrix:\n",
      "[[597 696]\n",
      " [149 713]]\n",
      "ROC AUC: 0.7235219807530465\n"
     ]
    }
   ],
   "source": [
    "# DNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "seed = 1100\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Focal Loss 定義\n",
    "def focal_loss(gamma=2, alpha=0.5):\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, dtype='float32')\n",
    "        pt = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        return -K.mean(alpha * K.pow(1. - pt, gamma) * K.log(pt + K.epsilon()))\n",
    "    return loss\n",
    "\n",
    "# 建構升級版 DNN\n",
    "model = Sequential([\n",
    "    Dense(256, kernel_regularizer=l2(0.001), input_shape=(X_train_transformed.shape[1],)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dropout(0.1),\n",
    "    Dense(128, kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dense(64, kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dense(32, kernel_regularizer=l2(0.001)),\n",
    "    LeakyReLU(alpha=0.1),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# 編譯\n",
    "optimizer = RMSprop(learning_rate=0.0005)\n",
    "model.compile(optimizer=optimizer, loss=focal_loss(), metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# 訓練\n",
    "model.fit(\n",
    "    X_train_transformed, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop, reduce_lr],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# 預測 + threshold 調整\n",
    "y_pred_prob = model.predict(X_test_transformed).flatten()\n",
    "threshold = 0.42\n",
    "y_pred = (y_pred_prob > threshold).astype(int)\n",
    "\n",
    "# 評估\n",
    "print(\"DNN 升級版 Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test, y_pred_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d87968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mf/55rzscrx4xv8ggsrxbx0q3c40000gn/T/ipykernel_942/3206440854.py:15: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
      "  shap.summary_plot(shap_values, X_test_transformed, feature_names=feature_list, show=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# 設定輸出目錄\n",
    "output_dir = \"../outputs\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 建立 SHAP explainer\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test_transformed)\n",
    "\n",
    "# Summary plot 存檔\n",
    "plt.figure()\n",
    "shap.summary_plot(shap_values, X_test_transformed, feature_names=feature_list, show=False)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig(os.path.join(output_dir, \"shap_summary.png\"), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Dependence plot（針對第一個變數，也可用名字取代）\n",
    "plt.figure()\n",
    "shap.dependence_plot(0, shap_values, X_test_transformed, feature_names=feature_list, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, \"shap_dependence_0.png\"), dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
